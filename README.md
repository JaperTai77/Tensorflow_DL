# Tensorflow_DL
### From tensorflow ZTM course

1. tf2_1.ipynb: Tensors/ Regression/ Cast dtype/ tf.squeeze,tf.expand_dims
2. tf2_2.ipynb: Classification(binary/multiclass)/ Tune learning rate/ Onehotencoding/ Visualize image/ Confusion matrix
3. tf2_3.ipynb: CNN(binary/multiclass)/ view image in notebook/ Overfitting(Maxpooling (dropout), Augmentation)/ prediction using user's image/ clone(copy) model/ save and load model
4. tf2_4.ipynb: Transfer learning/ feature extraction (tensorflow hub)/ Tensor Board Callback/ imagedatagenerator,imagedatasetfromdirectory/ functional API (tf.keras.application, Augmentation using functional API)/ globalaveragepooling/ Model check point (save weight, initial epochs)/ fine tunning (trainable)
5. tf2_5.ipynb: Build a model for food101/ Transfer learning(scaling up)/ save and load models to google drive/ prediction evaluation/ prediction evaluation(image)/ prediction evaluation(most wrong)/ prediction using user's image
6. tf2_6.ipynb: Food101 milestone/ convert shape and data type/ create batches/ mixed precision/ early stopping and reduce learning rate
7. tf2_7.ipynb: NLP/ shuffle/ tokenization/ embedding/ tensorflow projector/ RNN (LSTM/GRU)/ Bidirectional RNN/ CNN for NLP/ Transfer learning for NLP/ prediction ising user's text/ computing time compare 
8. tf2_8.ipynb: skimlit milestone/ process text file to dataframe/ Universal Sentence Emcoder/ character embedding/ combine char and token(Bidirectional)

- tf2_3.ipynb uses sequential API / tf2_4.ipynb uses functional API for computer vision

### From Book
a. LSTM_SentimentAnalysis.ipynb: NLP/ LSTM/ tokenization/ embedding/ text preprocessing(remove unused characters, lowercase)
