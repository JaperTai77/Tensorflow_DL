{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf2_7.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMTfAPKxheM+NODg07wf1vZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JaperTai77/Tensorflow_DL/blob/main/tf2_7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGEnLUySLGP8"
      },
      "source": [
        "# Natural Language Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xMSm4-mLU7n"
      },
      "source": [
        "## Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PEsAWjOLQPt"
      },
      "source": [
        "#### Get data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mk8mEeEdJ44",
        "outputId": "07d9666a-ecf9-4483-f9fe-3a99050505b0"
      },
      "source": [
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "f = \"nlp_getting_started.zip\"\n",
        "import zipfile\n",
        "zip_ref = zipfile.ZipFile(f, \"r\")\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-11-15 08:22:45--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.152.128, 209.85.200.128, 74.125.129.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.152.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-11-15 08:22:45 (103 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ie-RNXd8Ljwm",
        "outputId": "453a5726-7514-4af5-cd53-c6cad37baa93"
      },
      "source": [
        "import pandas as pd\n",
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "train.head()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVJoUOPrOQXJ"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KOYaf1UQxf8"
      },
      "source": [
        "#### Shuffle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "hIsIbN5uONEt",
        "outputId": "d7376dff-c4b4-4603-a59d-edd0f029225e"
      },
      "source": [
        "train = train.sample(frac = 1, random_state=42)\n",
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Djd7MVMTO51n",
        "outputId": "e5861c1a-f851-41ac-9b4e-7b61ebfc5631"
      },
      "source": [
        "train.target.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "li8A14zfQzU4"
      },
      "source": [
        "#### Split data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZJSsQsPQ1BS"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_sentence, val_sentence, train_label, val_label = train_test_split(train['text'].to_numpy(),\n",
        "                                                                        train['target'].to_numpy(),\n",
        "                                                                        test_size = 0.1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zn6PVLCR5eI",
        "outputId": "ade7f918-aabf-41b4-c677-3806c107956e"
      },
      "source": [
        "train_sentence[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([\"'There was a small earthquake in LA but don't worry Emily Rossum is fine' #difficultpeople is great\",\n",
              "       \"I'll cry until my pity party's in flames ????\",\n",
              "       \"There has not been 1 real tear out of #Shelli 's eyes this entire episode. #bb17\",\n",
              "       \"@FurTrix then find cougars who look like her even better if they're in military uniform!\",\n",
              "       \"'Sometimes God uses sorrowful tragedy to set the stage for glorious redemption.' -David Platt Run for\\x89Û_ https://t.co/86V81dv00E\",\n",
              "       'U.S National Park Services Tonto National Forest: Stop the Annihilation of the Salt River Wild Horse... https://t.co/m8MvDSPJp7 via @Change',\n",
              "       '\\x89ÛÏRichmond Coaches were devastated to hear of the death of their second driver Mr Chance who was sitting\\x89Û_: Jam... http://t.co/dIalTa6t69',\n",
              "       \"@asymbina @tithenai I'm hampered by only liking cross-body bags. I really like Ella Vickers bags: machine washable. http://t.co/YsFYEahpVg\",\n",
              "       '@r_lauren83199 @xojademarie124 i hope you get Batista Bombed lauren',\n",
              "       '@aphyr I\\x89Ûªve been following you this long\\x89Û_ Sunk cost fallacy or somethin\\x89Ûª'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4ewxk1zPWZf"
      },
      "source": [
        "#### Visualize random example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IQILJo9O947",
        "outputId": "99536d6c-94f2-4ede-eaa0-148c70d7da64"
      },
      "source": [
        "import random\n",
        "random_index = random.randint(0,len(train)-3)\n",
        "for row in train[['text','target']][random_index:random_index+3].itertuples():\n",
        "  _, text, target = row\n",
        "  print(f'Target: {target}', 'positive' if target == 0 else 'negative')\n",
        "  print(f'Text: \\n {text}')\n",
        "  print('------')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0 positive\n",
            "Text: \n",
            " Welcome @djryanwolf @djcoreygrand @djknyce @djoneplustwo @OfficialCoreDJs #Family #Cleveland #StandUp @IAMTONYNEAL http://t.co/P6GqmCTgLj\n",
            "------\n",
            "Target: 0 positive\n",
            "Text: \n",
            " @spookyfob @feelslikefob I am okay thank you yes your kindness is fatal though it's like Patrick stump level kindness.\n",
            "------\n",
            "Target: 1 negative\n",
            "Text: \n",
            " Hundreds feared drowned after another Mediterranean asylum seeker boat sinking http://t.co/zsYkzj2bzG\n",
            "------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sfxHDSmXUEzW"
      },
      "source": [
        "#### Tokenization (text vectorization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xpwTWQ5UKpT"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization as token\n",
        "\n",
        "text_vector = token(max_tokens = None, # Maximum size of the vocabulary\n",
        "                    standardize=\"lower_and_strip_punctuation\", # how to process text\n",
        "                    split = 'whitespace',\n",
        "\n",
        "                    ngrams=None, # no grouping, treat every token on its own\n",
        "                    output_mode=\"int\", # how to map tokens to numbers\n",
        "                    # define sequence length, so all input sequence are in the same length\n",
        "                    output_sequence_length=None, \n",
        "                    # pad_to_max_tokens=True (fill zeros to fit the length)\n",
        "                    # Not valid if using max_tokens=None\n",
        "                    )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rgkxZKjAXfXr",
        "outputId": "0cfe49b2-ca71-4061-a50a-377b94508e2a"
      },
      "source": [
        "# Set up vectorization\n",
        "max_vocab_length = 1000\n",
        "max_sent_length = 15\n",
        "\n",
        "text_vector = token(max_tokens=max_vocab_length,\n",
        "                    output_mode=\"int\",\n",
        "                    output_sequence_length=max_sent_length)\n",
        "\n",
        "# Transform\n",
        "text_vector.adapt(train_sentence)\n",
        "\n",
        "# example\n",
        "text_vector(['There is a car nearby.'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 75,   9,   3, 133, 642,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zUe_DJVgtia"
      },
      "source": [
        "Example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OysfHc4sfYsG"
      },
      "source": [
        "def random_tokenize(text = train_sentence):\n",
        "  random_sentence = random.choice(text)\n",
        "  print('Original text:\\n %s \\n\\n Vectorized version:\\n %s' \n",
        "        % (random_sentence,text_vector([random_sentence])))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8gm4e-kQoaq",
        "outputId": "7360d0e4-ef75-427d-9dd9-8970791207a5"
      },
      "source": [
        "random_tokenize()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " Debris confirmed from MH370; relatives hope for discovery of crash site: Malaysian officials confirm a breakth... http://t.co/MGYVGlENKS \n",
            "\n",
            " Vectorized version:\n",
            " tf.Tensor([[250 291  20 177   1 218  10   1   6  83 579   1 538   1   3]], shape=(1, 15), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ys_e4J5fgu7c"
      },
      "source": [
        "Get unique word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_1dY5X-gqOY",
        "outputId": "a795010c-8a88-40cc-9698-2168d5da6fd1"
      },
      "source": [
        "words = text_vector.get_vocabulary()\n",
        "wordstop5 = words[:5]\n",
        "wordslow5 = words[-5:]\n",
        "print(f\"Number of words in vocab: {len(words)}\")\n",
        "print(f\"Top 5 most common words: {wordstop5}\") \n",
        "print(f\"Bottom 5 least common words: {wordslow5}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 1000\n",
            "Top 5 most common words: ['', '[UNK]', 'the', 'a', 'in']\n",
            "Bottom 5 least common words: ['risk', 'reports', 'pradesh', 'patience', 'pamela']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXt1dqR9kLwS"
      },
      "source": [
        "#### Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YM2JrfyigfYa",
        "outputId": "6d75bcf4-1750-41c6-8679-3053b7a50129"
      },
      "source": [
        "import random\n",
        "embedding = tf.keras.layers.Embedding(input_dim=max_vocab_length, #input shape\n",
        "                                      output_dim = 128,\n",
        "                                      input_length = max_sent_length # length of each input\n",
        "                                      )\n",
        "\n",
        "embedding(text_vector([random.choice(train_sentence)]))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.04116246, -0.0365643 ,  0.01177046, ...,  0.00153387,\n",
              "          0.00119026,  0.04255948],\n",
              "        [-0.0441795 , -0.00272492, -0.00834078, ..., -0.01525576,\n",
              "         -0.03016746, -0.02198253],\n",
              "        [-0.0441795 , -0.00272492, -0.00834078, ..., -0.01525576,\n",
              "         -0.03016746, -0.02198253],\n",
              "        ...,\n",
              "        [ 0.03900604, -0.04213583,  0.01094236, ..., -0.00350801,\n",
              "          0.04636893, -0.01434063],\n",
              "        [-0.0441795 , -0.00272492, -0.00834078, ..., -0.01525576,\n",
              "         -0.03016746, -0.02198253],\n",
              "        [ 0.04630421,  0.03839452,  0.0183639 , ..., -0.01053084,\n",
              "         -0.03241856, -0.01439898]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aVhnBfJr6vX"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RC9DKExrr_uv"
      },
      "source": [
        "### Model 0 (Naive Bayes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9S0NSVnUlnml",
        "outputId": "4cbc7b51-63d7-4cde-a887-c71f1aeb9f9e"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "model0 = Pipeline([\n",
        "                  ('tfidf', TfidfVectorizer()),\n",
        "                  ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "model0.fit(train_sentence,train_label)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiyOsfTmtEZY",
        "outputId": "e08638b1-b53c-4677-dec5-43708809cb73"
      },
      "source": [
        "model0_score = model0.score(val_sentence,val_label)\n",
        "print('Model0 score: %s' %model0_score)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model0 score: 0.8097112860892388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF89EOu2tQx4",
        "outputId": "6a6869c2-8e0a-4755-a99b-820d827982f4"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "pred0 = model0.predict(val_sentence)\n",
        "print(classification_report(val_label, pred0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.92      0.83       433\n",
            "           1       0.86      0.61      0.72       329\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.81      0.77      0.77       762\n",
            "weighted avg       0.80      0.79      0.78       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V02CmpszHBr-"
      },
      "source": [
        "### Model 1 (Dense Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0LUnyrrHI_x",
        "outputId": "f3df20e8-b48c-4a93-920c-3983c0ece6df"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input = tf.keras.layers.Input(shape = (1,), dtype = tf.string)\n",
        "x = text_vector(input)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x) # condense each tokened feature vector to one vector\n",
        "# otherwise will return a prob for each word than for the whole sentence\n",
        "output = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model1 = tf.keras.Model(input,output, name = 'model1')\n",
        "model1.summary()"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           128000    \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 128)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 128,129\n",
            "Trainable params: 128,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5QT2RIUIZOF",
        "outputId": "8d15ad96-9f8e-4c22-b4c6-53ffdf10407e"
      },
      "source": [
        "model1.compile(loss = 'binary_crossentropy',\n",
        "               optimizer=tf.keras.optimizers.Adam(),\n",
        "               metrics = ['accuracy'])\n",
        "history1 = model1.fit(train_sentence, train_label, epochs = 5,\n",
        "                     validation_data = (val_sentence,val_label))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.6221 - accuracy: 0.6675 - val_loss: 0.5401 - val_accuracy: 0.7572\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.4972 - accuracy: 0.7773 - val_loss: 0.4612 - val_accuracy: 0.7940\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 1s 7ms/step - loss: 0.4439 - accuracy: 0.8072 - val_loss: 0.4352 - val_accuracy: 0.7966\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.4170 - accuracy: 0.8164 - val_loss: 0.4226 - val_accuracy: 0.7992\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 1s 6ms/step - loss: 0.4001 - accuracy: 0.8218 - val_loss: 0.4195 - val_accuracy: 0.8071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-TaQuMVLLW9",
        "outputId": "4065a25d-57de-465b-d4dd-db9d5619d0e0"
      },
      "source": [
        "model1.evaluate(val_sentence,val_label)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 4ms/step - loss: 0.4195 - accuracy: 0.8071\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4195030927658081, 0.8070865869522095]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2m0EPwHGLkt6",
        "outputId": "54c0e57a-d834-4fee-8961-6b7e4ebdd320"
      },
      "source": [
        "import numpy as np\n",
        "prob1 = model1.predict(val_sentence)\n",
        "print(np.round(prob1[0:5],3))\n",
        "pred1 = tf.squeeze(tf.round(prob1))"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.999]\n",
            " [0.928]\n",
            " [0.843]\n",
            " [0.999]\n",
            " [0.385]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbuLIdJBL-xr",
        "outputId": "44b8cdf6-2f4f-44fd-ca67-d611249aa44b"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val_label, pred1))"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.86      0.84       441\n",
            "           1       0.79      0.74      0.76       321\n",
            "\n",
            "    accuracy                           0.81       762\n",
            "   macro avg       0.80      0.80      0.80       762\n",
            "weighted avg       0.81      0.81      0.81       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT-EB0iJHGN4"
      },
      "source": [
        "#### Visualizing learned embeddings¶"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRZc0njJOncD",
        "outputId": "4ceadf2c-c4f8-4f01-b502-30ff7c664d6a"
      },
      "source": [
        "words = text_vector.get_vocabulary()\n",
        "print(len(words))\n",
        "embed_weight = model1.get_layer('embedding_1').get_weights()[0]\n",
        "embed_weight.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRSa4EGcRmek"
      },
      "source": [
        "128 vectors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmhhT79USYIO"
      },
      "source": [
        "http://projector.tensorflow.org (use chrome)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fToSgp_Cu8cU"
      },
      "source": [
        "import io\n",
        "\n",
        "# Create output writers\n",
        "out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# Write embedding vectors and words to file\n",
        "for num, word in enumerate(words):\n",
        "  if num == 0: \n",
        "      continue # skip padding token\n",
        "  vec = embed_weight[num]\n",
        "  out_m.write(word + \"\\n\") # write words to file\n",
        "  out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "# # Download files locally to upload to Embedding Projector\n",
        "# try:\n",
        "#   from google.colab import files\n",
        "# except ImportError:\n",
        "#   pass\n",
        "# else:\n",
        "#   files.download(\"embedding_vectors.tsv\")\n",
        "#   files.download(\"embedding_metadata.tsv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqFWzsiCT6LT"
      },
      "source": [
        "### Model 2 (RNN-LSTM)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnZ9yEurT_zi",
        "outputId": "767c5e84-0710-4d16-d721-93d1ec2c95bd"
      },
      "source": [
        "input = tf.keras.layers.Input(shape = (1,),dtype = tf.string)\n",
        "x = text_vector(input)\n",
        "print(x.shape)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = tf.keras.layers.LSTM(64,return_sequences= True)(x)\n",
        "# when stacking RNN cells, need to return sequence otherwise error\n",
        "print(x.shape) # (batch, timestamps, feature)\n",
        "x = tf.keras.layers.LSTM(64)(x)\n",
        "print(x.shape)\n",
        "x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
        "print(x.shape)\n",
        "output = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model2 = tf.keras.Model(input,output,name = 'model2')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15)\n",
            "(None, 15, 128)\n",
            "(None, 15, 64)\n",
            "(None, 64)\n",
            "(None, 64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JcUfkkAYYHG",
        "outputId": "c597edef-0900-4139-c91a-7af49a46b3fe"
      },
      "source": [
        "model2.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "               optimizer = tf.keras.optimizers.Adam(),\n",
        "               metrics = ['accuracy'])\n",
        "history2 = model2.fit(train_sentence,train_label,epochs = 5,\n",
        "                     validation_data = (val_sentence,val_label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 28ms/step - loss: 0.3879 - accuracy: 0.8342 - val_loss: 0.4823 - val_accuracy: 0.7979\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.3685 - accuracy: 0.8389 - val_loss: 0.4849 - val_accuracy: 0.8058\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.3593 - accuracy: 0.8453 - val_loss: 0.4846 - val_accuracy: 0.7887\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.3500 - accuracy: 0.8513 - val_loss: 0.4821 - val_accuracy: 0.8018\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.3351 - accuracy: 0.8610 - val_loss: 0.4811 - val_accuracy: 0.7861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Om_pISl2aUWr",
        "outputId": "eb5a033d-46bd-4c0f-a50e-59deeed00450"
      },
      "source": [
        "prob2 = model2.predict(val_sentence)\n",
        "pred2 = tf.squeeze(tf.round(prob2))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val_label, pred2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.87      0.82       433\n",
            "           1       0.80      0.67      0.73       329\n",
            "\n",
            "    accuracy                           0.79       762\n",
            "   macro avg       0.79      0.77      0.78       762\n",
            "weighted avg       0.79      0.79      0.78       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSzVkWEMkgBl"
      },
      "source": [
        "### Model 3 (GRU)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Est58Ukykkmn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c76644f-0eb2-4b64-ced9-de88db11af8a"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "input = tf.keras.layers.Input(shape = (1,), dtype = tf.string)\n",
        "x = text_vector(input)\n",
        "x = embedding(x)\n",
        "#x = tf.keras.layers.GRU(64,return_sequences = True)(x)\n",
        "#x = tf.keras.layers.LSTM(42,return_sequences = True)(x)\n",
        "x = tf.keras.layers.GRU(64)(x)\n",
        "x = tf.keras.layers.Dense(64, activation = 'relu')(x)\n",
        "output = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model3 = tf.keras.Model(input,output)\n",
        "model3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding_1 (Embedding)     (None, 15, 128)           128000    \n",
            "                                                                 \n",
            " gru (GRU)                   (None, 64)                37248     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,473\n",
            "Trainable params: 169,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBGbEVN4kwAj",
        "outputId": "619e01aa-1061-47dc-a427-c31cc5034b2b"
      },
      "source": [
        "model3.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = tf.keras.optimizers.Adam(),\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "history3 = model3.fit(train_sentence, train_label,epochs = 5,\n",
        "                     validation_data = (val_sentence, val_label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 12ms/step - loss: 0.5394 - accuracy: 0.7157 - val_loss: 0.4833 - val_accuracy: 0.7677\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.4213 - accuracy: 0.8121 - val_loss: 0.4719 - val_accuracy: 0.7848\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3985 - accuracy: 0.8275 - val_loss: 0.5137 - val_accuracy: 0.7533\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3782 - accuracy: 0.8368 - val_loss: 0.4779 - val_accuracy: 0.7769\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 9ms/step - loss: 0.3521 - accuracy: 0.8507 - val_loss: 0.5030 - val_accuracy: 0.7743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPxuwNQnmqi8",
        "outputId": "31f94728-b683-4bce-a3b1-cdd17f26e80c"
      },
      "source": [
        "prob3 = model3.predict(val_sentence)\n",
        "pred3 = tf.squeeze(tf.round(prob3))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val_label, pred3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.86      0.81       433\n",
            "           1       0.78      0.66      0.72       329\n",
            "\n",
            "    accuracy                           0.77       762\n",
            "   macro avg       0.78      0.76      0.76       762\n",
            "weighted avg       0.78      0.77      0.77       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiUymVrgnMCE"
      },
      "source": [
        "### Model 4 (Bidirectional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tn9k5iKSnNUn",
        "outputId": "a257eeea-d13e-4f55-859b-7b34c703036f"
      },
      "source": [
        "input = tf.keras.layers.Input(shape = (1,), dtype = tf.string)\n",
        "x = text_vector(input)\n",
        "x = embedding(x)\n",
        "print(x.shape)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64,return_sequences = True))(x)\n",
        "print(x.shape)\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(64))(x)\n",
        "print(x.shape)\n",
        "output = tf.keras.layers.Dense(1,activation = 'sigmoid')(x)\n",
        "model4 = tf.keras.Model(input,output)\n",
        "model4.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n",
            "(None, 15, 128)\n",
            "(None, 128)\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           128000    \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirectio  (None, 15, 128)          98816     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 128)              74496     \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 301,441\n",
            "Trainable params: 301,441\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm747b1etBOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d2337d-7899-4cab-ac2b-e6f4f83af1e3"
      },
      "source": [
        "model4.compile(loss = 'binary_crossentropy',\n",
        "               optimizer = tf.keras.optimizers.Adam(),\n",
        "               metrics = 'accuracy')\n",
        "history4 = model4.fit(train_sentence, train_label,epochs = 5,\n",
        "                     validation_data = (val_sentence,val_label))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 19s 31ms/step - loss: 0.5219 - accuracy: 0.7352 - val_loss: 0.4734 - val_accuracy: 0.7743\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.4161 - accuracy: 0.8137 - val_loss: 0.4595 - val_accuracy: 0.7992\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.3857 - accuracy: 0.8320 - val_loss: 0.4769 - val_accuracy: 0.7769\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 5s 24ms/step - loss: 0.3511 - accuracy: 0.8501 - val_loss: 0.4967 - val_accuracy: 0.7795\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 5s 23ms/step - loss: 0.3226 - accuracy: 0.8626 - val_loss: 0.5508 - val_accuracy: 0.7717\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m2DCgL7CtoHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d115225-83c9-439e-c2ed-1ea809eaaf6f"
      },
      "source": [
        "prob4 = model4.predict(val_sentence)\n",
        "pred4 = tf.squeeze(tf.round(prob4))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val_label, pred4))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.92      0.82       432\n",
            "           1       0.85      0.57      0.68       330\n",
            "\n",
            "    accuracy                           0.77       762\n",
            "   macro avg       0.80      0.75      0.75       762\n",
            "weighted avg       0.79      0.77      0.76       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsIYD64QAqXg"
      },
      "source": [
        "### Model 5 (Conv1D)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XzBlhtDaAttf",
        "outputId": "87b1ce40-a938-4901-f664-d9c0f6690be2"
      },
      "source": [
        "embedding_test = embedding(text_vector(['This is a sample sentence']))\n",
        "conv1d = tf.keras.layers.Conv1D(filters=32,\n",
        "                                kernel_size = 5, # 5 words at a time\n",
        "                                strides = 1, # hop through one at a time\n",
        "                                activation = 'relu',\n",
        "                                padding = 'same') # don't change output size\n",
        "conv1d_out = conv1d(embedding_test)\n",
        "max_pool = tf.keras.layers.GlobalMaxPool1D() \n",
        "# get the most important parameter\n",
        "max_pool_out = max_pool(conv1d_out)\n",
        "\n",
        "print(embedding_test.shape, conv1d_out.shape, max_pool_out.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 15, 128) (1, 15, 32) (1, 32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2IUx2Q_4aFC",
        "outputId": "70d8684f-f618-46e0-e4dc-b17f8fa950e1"
      },
      "source": [
        "import tensorflow as tf\n",
        "input = tf.keras.layers.Input(shape = (1,), dtype = tf.string)\n",
        "x = text_vector(input)\n",
        "x = embedding(x)\n",
        "x = tf.keras.layers.Conv1D(filters = 64,kernel_size = 5, strides = 1, \n",
        "                           activation = 'relu', padding = 'valid')(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "# x = tf.keras.layers.Dense(64, activation = 'relu')\n",
        "output = tf.keras.layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model5 = tf.keras.Model(input,output)\n",
        "\n",
        "model5.compile(loss = 'binary_crossentropy',\n",
        "              optimizer = 'Adam',\n",
        "              metrics = ['accuracy'])\n",
        "model5.summary()  "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 1)]               0         \n",
            "                                                                 \n",
            " text_vectorization_1 (TextV  (None, 15)               0         \n",
            " ectorization)                                                   \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 15, 128)           128000    \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 11, 64)            41024     \n",
            "                                                                 \n",
            " global_average_pooling1d_1   (None, 64)               0         \n",
            " (GlobalAveragePooling1D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 169,089\n",
            "Trainable params: 169,089\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlx9Y4NWKYOo",
        "outputId": "dc67f6d0-3b39-45d2-9657-a7a4da84d72f"
      },
      "source": [
        "history5 = model5.fit(train_sentence,train_label, epochs = 5, validation_data = (val_sentence,val_label))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 9ms/step - loss: 0.5444 - accuracy: 0.7187 - val_loss: 0.4771 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.4248 - accuracy: 0.8067 - val_loss: 0.4901 - val_accuracy: 0.7507\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.3984 - accuracy: 0.8159 - val_loss: 0.4852 - val_accuracy: 0.7690\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 2s 7ms/step - loss: 0.3730 - accuracy: 0.8349 - val_loss: 0.4982 - val_accuracy: 0.7493\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 2s 8ms/step - loss: 0.3518 - accuracy: 0.8463 - val_loss: 0.5132 - val_accuracy: 0.7743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc_bfAx_Kwyr",
        "outputId": "d0976e07-317e-4296-a873-f302270bb44a"
      },
      "source": [
        "prob5 = model5.predict(val_sentence)\n",
        "pred5 = tf.squeeze(tf.round(prob5))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val_label, pred5))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.89      0.82       435\n",
            "           1       0.81      0.62      0.70       327\n",
            "\n",
            "    accuracy                           0.77       762\n",
            "   macro avg       0.78      0.75      0.76       762\n",
            "weighted avg       0.78      0.77      0.77       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH-cjPl-K4DR"
      },
      "source": [
        "### Model 6 (Transfer learning)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ellPTf-vK9kh"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFkW227YNYsK",
        "outputId": "6af40add-6735-4073-9586-77e9e17ee4f2"
      },
      "source": [
        "import tensorflow as tf\n",
        "encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                               input_shape = [], # model does not need input shape\n",
        "                               dtype = tf.string,\n",
        "                               trainable = False,\n",
        "                               name = 'USE')\n",
        "\n",
        "model6 = tf.keras.Sequential([\n",
        "                              encoder_layer,\n",
        "                              tf.keras.layers.Dense(64, activation = 'relu'),\n",
        "                              tf.keras.layers.Dense(1,activation = 'sigmoid')\n",
        "                              ], name = 'model6')\n",
        "\n",
        "model6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model6.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense (Dense)               (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WAgnzlIVOid3",
        "outputId": "d16fcde7-37bc-4871-ccb6-09eff3827b67"
      },
      "source": [
        "history6 = model6.fit(train_sentence, train_label,\n",
        "                     epochs = 5, validation_data = (val_sentence,val_label))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "215/215 [==============================] - 10s 22ms/step - loss: 0.5050 - accuracy: 0.7727 - val_loss: 0.4270 - val_accuracy: 0.8018\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.4142 - accuracy: 0.8187 - val_loss: 0.4131 - val_accuracy: 0.8045\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.4015 - accuracy: 0.8221 - val_loss: 0.4088 - val_accuracy: 0.8123\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3934 - accuracy: 0.8283 - val_loss: 0.4087 - val_accuracy: 0.8136\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 4s 20ms/step - loss: 0.3866 - accuracy: 0.8292 - val_loss: 0.4056 - val_accuracy: 0.8215\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4YflYgROzSd",
        "outputId": "ec173348-90fd-4c29-cb3b-56ebffbaa61d"
      },
      "source": [
        "prob6 = model6.predict(val_sentence)\n",
        "pred6 = tf.squeeze(tf.round(prob6))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val_label, pred6))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       441\n",
            "           1       0.82      0.74      0.78       321\n",
            "\n",
            "    accuracy                           0.82       762\n",
            "   macro avg       0.82      0.81      0.81       762\n",
            "weighted avg       0.82      0.82      0.82       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zGdqga4pQr7I"
      },
      "source": [
        "### Model 7 (10% data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hdgITkmQys2"
      },
      "source": [
        "train10 = train[['text', 'target']].sample(frac = 0.1)\n",
        "train10_sentence = train10['text'].to_list()\n",
        "train10_label = train10['target'].to_list()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u_5IP4JURVDT",
        "outputId": "1d9a5bab-532b-487e-9d80-01768b7d5a7a"
      },
      "source": [
        "train10['target'].value_counts()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    420\n",
              "1    341\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nMeryWrVRg4b",
        "outputId": "25807fcc-af1e-4acc-cb43-67643e3cd181"
      },
      "source": [
        "model7 = tf.keras.models.clone_model(model6)\n",
        "\n",
        "model7.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "               optimizer = tf.keras.optimizers.Adam(),\n",
        "               metrics = ['accuracy'])\n",
        "model7.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " USE (KerasLayer)            (None, 512)               256797824 \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                32832     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glJmGInPSiFv",
        "outputId": "3e1b6894-3d8a-4e5d-9033-947182fc24e2"
      },
      "source": [
        "model7.fit(train10_sentence, train10_label, epochs = 5, validation_data = (train_sentence,train_label))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "24/24 [==============================] - 7s 182ms/step - loss: 0.6739 - accuracy: 0.6189 - val_loss: 0.6463 - val_accuracy: 0.7468\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 4s 161ms/step - loss: 0.6065 - accuracy: 0.8042 - val_loss: 0.5780 - val_accuracy: 0.7819\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 4s 162ms/step - loss: 0.5308 - accuracy: 0.8160 - val_loss: 0.5167 - val_accuracy: 0.7844\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 4s 161ms/step - loss: 0.4685 - accuracy: 0.8239 - val_loss: 0.4790 - val_accuracy: 0.7913\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 4s 161ms/step - loss: 0.4261 - accuracy: 0.8357 - val_loss: 0.4576 - val_accuracy: 0.7936\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efdc012e050>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTWaoDfXSw9R",
        "outputId": "1ada196f-386a-40d8-9e8a-40ab2767e947"
      },
      "source": [
        "model7.evaluate(val_sentence,val_label)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 16ms/step - loss: 0.4848 - accuracy: 0.7717\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4847722053527832, 0.7716535329818726]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vk9VGITgS0_a",
        "outputId": "88f00ae7-5e06-4b19-e203-1717725bc357"
      },
      "source": [
        "prob7 = model7.predict(val_sentence)\n",
        "pred7 = tf.squeeze(tf.round(prob7))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(val_label, pred7))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.80       435\n",
            "           1       0.74      0.72      0.73       327\n",
            "\n",
            "    accuracy                           0.77       762\n",
            "   macro avg       0.77      0.77      0.77       762\n",
            "weighted avg       0.77      0.77      0.77       762\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-v5zSuwJT8Xq"
      },
      "source": [
        "There will be data leakage problem, since some validation data are in train data.\\\n",
        "Validation data took from"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLKovWgntE7s"
      },
      "source": [
        "# Correct split\n",
        "_, train10_sentence, _, train10_label = train_test_split(np.array(train_sentences),\n",
        "                                                                                    train_labels,test_size=0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_aQlIjKHu-7f"
      },
      "source": [
        "### Save best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKfv2VYYvCd-"
      },
      "source": [
        "model6.save('NLP_model.h5')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OMFSsdAMvdiO"
      },
      "source": [
        "# Import transfer learning model\n",
        "import tensorflow_hub as hub\n",
        "loaded_model = tf.keras.models.load_model('NLP_model.h5',\n",
        "                                          custom_objects = {'KerasLayer':hub.KerasLayer}\n",
        "                                          # for encoder_layer which we used in model6\n",
        "                                          )"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HetkE854wV1N",
        "outputId": "52dbf573-be9a-47c8-9171-56bc6a45e7f6"
      },
      "source": [
        "model6.evaluate(val_sentence,val_label) == loaded_model.evaluate(val_sentence,val_label)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 18ms/step - loss: 0.4056 - accuracy: 0.8215\n",
            "24/24 [==============================] - 1s 17ms/step - loss: 0.4056 - accuracy: 0.8215\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB1C1fEjwi98",
        "outputId": "cf021454-c057-4cde-d918-407639b13b72"
      },
      "source": [
        "# Save model format\n",
        "model6.save('NLP_model')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) USE_input with unsupported characters which will be renamed to use_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: NLP_model/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: NLP_model/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpGteboLw1qq",
        "outputId": "7019aba7-cad1-48db-a1e7-cba3d577b9e1"
      },
      "source": [
        "loaded_model = tf.keras.models.load_model(\"NLP_model\")\n",
        "model6.evaluate(val_sentence,val_label) == loaded_model.evaluate(val_sentence,val_label)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24/24 [==============================] - 0s 17ms/step - loss: 0.4056 - accuracy: 0.8215\n",
            "24/24 [==============================] - 1s 17ms/step - loss: 0.4056 - accuracy: 0.8215\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zJRigs8sxPji"
      },
      "source": [
        "## Inspection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Em7tfR_7xRo0"
      },
      "source": [
        "prob6 = model6.predict(val_sentence)\n",
        "pred6 = tf.squeeze(tf.round(prob6))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K00bBM0FyDw3"
      },
      "source": [
        "df = pd.DataFrame({'text':val_sentence, 'true_label': val_label,'pred_label': pred6})\n",
        "df['probability'] = prob6"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "BoJAm6TqyFyQ",
        "outputId": "9d670dc2-996e-42d5-9117-6cf1e5ddb84c"
      },
      "source": [
        "df['prob'] = df.apply(lambda x: x['probability'] if x['pred_label']== 1 else 1-x['probability'],axis = 1)\n",
        "df = df.drop(columns=['probability'])\n",
        "df['accuracy'] = df.apply(lambda x: 1 if x['true_label'] == x['pred_label'] else 0, axis = 1)\n",
        "df.head()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>true_label</th>\n",
              "      <th>pred_label</th>\n",
              "      <th>prob</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Families to sue over Legionnaires: More than 4...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.973461</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Governor allows parole for California school b...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.910551</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.967180</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>...//..// whao.. Pic of 16yr old PKK suicide b...</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.985293</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>the stars are burning i here your voice in my ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.913602</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...  accuracy\n",
              "0  Families to sue over Legionnaires: More than 4...  ...         1\n",
              "1  Governor allows parole for California school b...  ...         1\n",
              "2  Police investigating after an e-bike collided ...  ...         1\n",
              "3  ...//..// whao.. Pic of 16yr old PKK suicide b...  ...         1\n",
              "4  the stars are burning i here your voice in my ...  ...         1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWGa2hvVyZt7"
      },
      "source": [
        "df_wrong = df[df['accuracy'] != 1].sort_values(by = 'prob',ascending = False)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1lKb-EW1BkA",
        "outputId": "b6bf1c52-f609-4501-e6c2-ac0b9d65e049"
      },
      "source": [
        "for row in df_wrong[:20].itertuples():\n",
        "  _,text,target,pred,prob,acc = row\n",
        "  print(f\"Target: {target}, Pred: {int(pred)}, Prob: {prob}\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"----\\n\")"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 0, Pred: 1, Prob: 0.9769226312637329\n",
            "Text:\n",
            "Teen Disaster Preparedness Event in Van Nuys August 11 @ 5:30pm http://t.co/fXUX987vZx via @VanNuysCouncil\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.974400520324707\n",
            "Text:\n",
            "Mourning notices for stabbing arson victims stir Û÷politics of griefÛª in Israel: Posters for Shira Banki and A... http://t.co/3GZ5zQQTHe\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9649578295648098\n",
            "Text:\n",
            "@HaydnExists so glad i saved them all at once then didnÛªt want you stealing my thunder :P\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9646433591842651\n",
            "Text:\n",
            "Two Jewish Terrorists Charged In Historic-Church Arson | The Ugly Truth http://t.co/iEksNFSbY7 http://t.co/VWCf3slkrW\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9449977837502956\n",
            "Text:\n",
            "Just made anthonys bed considering i destroy it everytime i fall asleep. Smh ????\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9406877979636192\n",
            "Text:\n",
            "SANDSTORM!!! WOO HOO!!\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9370287135243416\n",
            "Text:\n",
            "I went to pick up my lunch today and the bartender was holding my change hostage because he wanted my number. ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9341879412531853\n",
            "Text:\n",
            "@allen_enbot If you mess up it's gonna explode...\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9261409342288971\n",
            "Text:\n",
            "@DavidVonderhaar At least you were sincere ??\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9249242171645164\n",
            "Text:\n",
            "Lucas Duda is Ghost Rider. Not the Nic Cage version but an actual 'engulfed in flames' badass. #Mets\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9185386300086975\n",
            "Text:\n",
            "? High Skies - Burning Buildings ? http://t.co/uVq41i3Kx2 #nowplaying\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9173299819231033\n",
            "Text:\n",
            "@Zak_Bagans this is Sabrina my dad rescued her from some dude who kept her in a cage. We've had her since I was 4 http://t.co/1k2PhQcuW8\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9136819243431091\n",
            "Text:\n",
            "Fire hazard associated with installation of non-compliant external cladding on high-rise buildings - Insurance - Aust http://t.co/wFsEaOBATo\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9116768538951874\n",
            "Text:\n",
            ".@karijobe and her band killed it tonight.  It was almost loud enough to drown out the tambourine behind me..... @codycarnes @AG_USA\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9094461053609848\n",
            "Text:\n",
            "my favorite lady came to our volunteer meeting\n",
            "hopefully joining her youth collision and i am excite http://t.co/Ij0wQ490cS\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9081733003258705\n",
            "Text:\n",
            "@KopiteLuke1892 Its broken its fully exploded.\n",
            "\n",
            "----\n",
            "\n",
            "Target: 0, Pred: 1, Prob: 0.9078369736671448\n",
            "Text:\n",
            "One thing for sure-God has promised Israel will not be annihilated. But...the horror of Iran w/nukes. https://t.co/xn09Mx6sxy\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9076759368181229\n",
            "Text:\n",
            "I JUST SCREAMED @toddyrockstar http://t.co/JDtPirnm76\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9062134325504303\n",
            "Text:\n",
            "@TheHammers_ @tonycottee1986 alsowhat if some of the 1st team players got injured?Then Bilic would get slated for playing themhe can't win\n",
            "\n",
            "----\n",
            "\n",
            "Target: 1, Pred: 0, Prob: 0.9061178714036942\n",
            "Text:\n",
            "@BubblyCuteOne ?????????? ok ok okayyyyyy Ima act right ....bout to get this blizzard tho\n",
            "\n",
            "----\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liNf_2iv27-T"
      },
      "source": [
        "def model_prediction(sent, model = model6):\n",
        "  prob = model.predict([sent])\n",
        "  pred = tf.squeeze(tf.round(prob)).numpy()\n",
        "  print(f\"Pred: {pred}\", \"(real disaster)\" if pred > 0 else \"(not real disaster)\", f\"Prob: {prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sent}\")"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9yMiyRz4eST",
        "outputId": "5ff52fa9-9e8d-4ace-9239-049b56071184"
      },
      "source": [
        "text = input('Enter a sentence')\n",
        "model_prediction(sent=text)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter a sentence\"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n",
            "Pred: 1.0 (real disaster) Prob: 0.9800093770027161\n",
            "Text:\n",
            "\"Reports that the smoke in Beirut sky contains nitric acid, which is toxic. Please share and refrain from stepping outside unless urgent. #Lebanon\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkJEwqCh88Do"
      },
      "source": [
        "import time\n",
        "def pred_timer(model, samples):\n",
        "  start_time = time.perf_counter() # get start time\n",
        "  model.predict(samples) # make predictions\n",
        "  end_time = time.perf_counter() # get finish time\n",
        "  total_time = end_time-start_time # calculate how long predictions took to make\n",
        "  time_per_pred = total_time/len(val_sentence) # find prediction time per sample\n",
        "  return total_time, time_per_pred\n",
        "\n",
        "model_6_total_pred_time, model_6_time_per_pred = pred_timer(model6, val_sentence)\n",
        "baseline_total_pred_time, baseline_time_per_pred = pred_timer(model0, val_sentence)\n",
        "model_1_total_pred_time, model_1_time_per_pred = pred_timer(model1, val_sentence)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10, 7))\n",
        "plt.scatter(model_1_time_per_pred, model_1_results[\"f1\"], label=\"simple_network\")\n",
        "plt.scatter(baseline_time_per_pred, baseline_results[\"f1\"], label=\"baseline\")\n",
        "plt.scatter(model_6_time_per_pred, model_6_results[\"f1\"], label=\"tf_hub_sentence_encoder\")\n",
        "plt.legend()\n",
        "plt.title(\"F1-score versus time per prediction\")\n",
        "plt.xlabel(\"Time per prediction\")\n",
        "plt.ylabel(\"F1-Score\");\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}